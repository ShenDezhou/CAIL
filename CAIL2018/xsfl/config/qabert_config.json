{
  "model_type": "bert",
  "max_seq_len": 500,
  "model_path": "model/qabert/",
  "log_path": "log/",

  "train_file_path": "data/cail2018_train.csv",
  "valid_file_path": "data/fs_test.csv",

  "batch_size": 4,


  "bert_model_path": "../roberta_wwm_ext_qa",
  "trained_weight":"",
  "hidden_size": 768,
  "per_class_size": 1024,
  "num_classes": 202,
  "dropout": 0.05,

  "lr": 1e-4,
  "num_epoch": 1,
  "num_warmup_steps": 0,
  "num_training_steps": 32000,
  "gradient_accumulation_steps": 1,
  "max_grad_norm": 3e-3,

  "num_cores": 8,
  "serial_load": true,
  "metrics_debug": false,
  "log_steps": 100,

  "experiment_name": "QABERT"
}