[train] #train parameters
epoch = 10
batch_size = 16
shuffle = True
reader_num = 0
optimizer = adam
learning_rate = 3e-3
step_size = 1
lr_multiplier = 1
gradient_accumulation_steps=1
max_grad_norm=1e-2

[eval] #eval parameters
batch_size = 16
shuffle = False
reader_num = 0

[data]
train_dataset_type=JsonFromFiles
train_formatter_type=BertWordFormatter
train_data_path=input/
train_file_list=train_data_train.json

valid_dataset_type=JsonFromFiles
valid_formatter_type=BertWordFormatter
valid_data_path=input/
valid_file_list=train_data_test.json

test_dataset_type=JsonFromFiles
test_formatter_type=BertWordFormatter
test_data_path=/input/
test_file_list=0_test.json,1_test.json

max_question_len = 128
max_option_len = 64
word2id = data/word2id.txt

[model]
model_name=ModelX
bert_path=../bert_wwm
max_seq_len=512
dropout=0.05
hidden_size = 768
bi_direction = True
num_layers = 2

[output]
output_time=1
test_time=1
model_path=output/model
model_name=bert_wwm
tensorboard_path=output/bert_wwm/tensorboard

accuracy_method=MultiLabelTop1
output_function=Basic
output_value=micro_precision
