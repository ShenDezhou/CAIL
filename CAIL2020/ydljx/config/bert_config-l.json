{
  "model_type": "bert",
  "max_seq_len": 512,
  "max_query_len": 50,
  "model_path": "data_model/",
  "data_dir": "data_model",
  "log_path": "log/",

  "train_file_path": "private/dev.csv",
  "valid_file_path": "private/dev.csv",

  "batch_size": 8,

  "bert_model_path": "/mnt/data/torchcail/bert-base-chinese",
  "input_dim": 768,
  "label_type_num": 4,
  "num_classes": 2,
  "dropout": 0.20,

  "lr": 5e-4,
  "num_epoch": 2,
  "num_warmup_steps": 1,
  "num_training_steps": 32000,
  "gradient_accumulation_steps": 8,
  "max_grad_norm": 1e-3,

  "experiment_name": "BERT",
  "eval_batch_size": 8,
  "model_gpu": 0
}