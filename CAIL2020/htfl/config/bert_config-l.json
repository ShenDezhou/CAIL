{
  "model_type": "bert",
  "max_seq_len": 512,
  "model_path": "model/bert/",
  "log_path": "log/",

  "train_file_path": "data/train.csv",
  "valid_file_path": "data/valid.csv",

  "batch_size": 8,

  "bert_model_path": "/mnt/data/torchcail/bert-base-chinese",
  "trained_weight":"model/bert/model.bin",
  "hidden_size": 768,
  "num_classes": 24,
  "dropout": 0.50,

  "lr": 1e-5,
  "num_epoch": 50,
  "num_warmup_steps": 2000,
  "num_training_steps": 32000,
  "gradient_accumulation_steps": 16,
  "max_grad_norm": 1e-3,

  "experiment_name": "BERT"
}