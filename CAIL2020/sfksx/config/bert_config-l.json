{
  "model_type": "bert",
  "max_seq_len": 512,
  "model_path": "model/bert/",
  "log_path": "log/",

  "train_file_path": "private/train.csv",
  "valid_file_path": "private/valid.csv",

  "batch_size": 16,

  "bert_model_path": "/mnt/data/torchcail/bert-base-chinese",
  "hidden_size": 768,
  "num_classes": 2,
  "dropout": 0.20,

  "lr": 5e-4,
  "num_epoch": 4,
  "num_warmup_steps": 1,
  "num_training_steps": 32000,
  "gradient_accumulation_steps": 8,
  "max_grad_norm": 1e-3,

  "experiment_name": "BERT"
}